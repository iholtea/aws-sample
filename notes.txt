https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/home.html

https://docs.aws.amazon.com/lambda/latest/dg/welcome.html
https://docs.aws.amazon.com/serverless/latest/devguide/serverless-building-apps.html

https://www.srvrlss.io/blog/Amazon-Lambda-docker/

https://www.coursera.org/learn/building-modern-java-applications-on-aws
https://www.coursera.org/learn/building-modern-java-applications-on-aws/home/week/1

https://www.coursera.org/learn/dynamodb-nosql-database-driven-apps
https://www.coursera.org/learn/dynamodb-nosql-database-driven-apps/home/week/1

https://bobbyhadz.com/blog/aws-list-all-resources
Also another good place to start is the billing console

aws lambda invoke --function-name FirstLambda \ 
--cli-binary-format raw-in-base64-out \ 
--payload file://first-lambda-test-02.json out.json

!! See how to create a nice readme.md in github
you can upload images into an img folder and then use them from the readme
https://github.com/awsdocs/aws-doc-sdk-examples/blob/main/javav2/usecases/creating_lambda_apigateway/Readme.md

IAM Roles

A service-linked role is a unique type of IAM role that is linked directly to an AWS service. 
Service-linked roles are predefined by the service and include all the permissions 
that the service requires to call other AWS services on your behalf. 

AWSServiceRoleForSupport
AWSServiceRoleForTrustedAdvisor
    They are Service-Linked Role
    q1: why do they appear in my Roles list in AWS console ?
        I did not create them since they are predefined by AWS, maybe they pop up in that 
        list when the services to which they are linked are used for the first time ?
    q2: I might have screwed up by deleting a Cloud9 service linked role ?
        why did AWS let me delete it if it's predefined by an AWS service :) ?

NOTE
    I think it would be a good practice to tag anything I create in AWS with 
    created-by : iholtea so I know what to delete and what might be stuff created by AWS

https://aws.amazon.com/developer/tools/
    Tools for developing and managing applications on AWS

NOTE
    it would seem one way to enable an aws service to make use of another aws service
    is to use Roles. You attach a role to the first service that grants permissions to 
    access the sencond service. 

 Parameter store
    to use key-value pairs to keep names of aws resources in case they will change
    for example names of the s3 buckets used by an application  

 NoSQL
    in DynamoDB if creating a Books table, we may have Book Title + Author Name as partition key
    but then we want to search also by author name and by book title

    check JavaBrains Cassandra tutorial here: https://www.youtube.com/watch?v=106jIBE9XSc
    We might have a BookById table, and BookByAuthor table 
    Having just book title as partition key is not ideal, as multiple books may have the same title
    (written by different authors)
    Note that we may have multiple entries with the same partition key, it is expected
    so an author name/id can be PK in the BooksByAuthor table because we want to display 
    all the books written be an author when displaying authord details

    but having book title + author name as partition key , i don't know if we could have 
    two additional "indexes" both for book title and for author name to search by both  

 Security related :

    Resource policy
        is attached to a resource like an S3 bucket and specifies what actions are allowed 
        on that resource

    Identity policy
        specifies what services/resources that identity can access.
        ( probably it's not enough for example to attach a role to lambda that it can access S3 buckets
        if the specific bucket does not have a policy to allow actions to be executed)

    Also, the thing with identity policy is that we may add them only for services in our account.
    If we need to allow other account to access different resources we need resource policies

    Bucket policies (check https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html)

    Deny access exception some IP address class

    {
      "Version": "2012-10-17",
      "Id": "BlockIPAddr",
      "Statement": [
        {
          "Sid": "IPAllow",
          "Effect": "Deny",
          "Principal": "*",
          "Action": "s3:*",
          "Resource": "arn:aws:s3:::test-usage-iholtea/*",
          "Condition": {
            "NotIpAddress": {
                "aws:SourceIp": "1.3.3.5/32"
            }        
          }
        }
      ]
    }

    Create a static website with S3

        step 1: create a bucket with the chosen name , uncheck Block Public Access 
            leave the rest default and hit Create Bucket

        step 2: 
            click on the bucket -> properties tab
            scroll to the bottom the the Static website hosting section and hit Edit   
            check enable
            provide the index and error document html file names
              for example index.html and error.html
            click on Save changes button
        
            At this point if we access the linked provided by AWS for the site like
            http://test-static-site-iholtea.s3-website-us-east-1.amazonaws.com 
            we get 403 Forbidden  Code: AccessDenied
            By default S3 is private and since we did not set any permission to 
            access the objects from this bucket
            NOTE - now we are accessing it from the internet, so as an anonymous
            or un-authenticated user( as opposed when accessing it from a a java client
            using AWS API and having the Admin credentials set up)

        step 3:
            add a bucket policy to enable access
            go to Permission tab in the bucket and edit the Bucket policy

            {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Sid": "PublicRead",
                        "Effect": "Allow",
                        "Principal": "*",
                        "Action": "s3:GetObject",
                        "Resource": "arn:aws:s3:::test-static-site-iholtea/*"
                    }
                ]
            }

API Gateway - there are multiple types
    Websocket
        statefull and bi-directional communication. Used for real-time apps like chats.
    Http 
        used to proxy back-end resources and are supposed to be simple and fast.
        supports authentication, can call lambda functions
        so it takes a request, authorises it and passes to the backend implementation(lambda, other http endpoint)
    REST
        similar with Http but has additional functionality.
        gives control over the request and response, validation, transformation of the data payload,
        may provide mocked responses.

Create a new API.
    go to API Gateway, choose REST API and click Build
    select New API type
    give it a name: todos-manual 

Create a Resource - this is like and endpoint to which we then can add methods.
    click Create Resource 
    give it a name like hello. The path will hava the same name.
    now we have the hello resource and by default it has the http OPTIONS method

Create a Method for a Resource
    
    select type - GET/POST/DELETE etc
    select integration type - Lambda, Mock, Http endpoint     
    
    after creation we can control what happens during the request/response flow
    Method Request settings 
        apply authorization, validate data payload
    Integration request 
        specify integration type like Mock, Lambda
        apply data transformation on payload if necessary
    Integration response 
        this is an http response encapsulating the backend response    
        so we cand configure how backed response maps to http response
        we can apply data transformation
    Method response settings
        can apply validations on the response data
        specify how to send different http status codes and associated headers/payload 

    Test tab where we could add query strings and headers and test the current method

    Models: 
        validate request/responses with models
        defines the structure of the request
        are created using JSON schemas
        if the request payload does not match the schema API gateway will return a 
            400 error http response. So no need to call lamba/backend for this taskß 
    Mappings: transform request/responses with mappings 
        might be needed when backend expects the data in a format different
        from the one the client sends.  
        mapping are written in VTL - velocity template language 

To create an integration response for a Mock type method
    Click Edit on the response. There is a default one for 200 status code
    Expand Mapping templates and add the json body we want to return as mock
    Ex for a HelloWorld:
    {
      "message": "hello, world!"
    }

    Use VTL instead of just plain JSON to create a dynamic response 
    depending on query string parameters
    see https://docs.aws.amazon.com/apigateway/latest/developerguide/models-mappings.html
    
    #set($name=$input.params('name'))
    #set($lang=$input.params('lang'))
    #if( $lang == 'ro' )
      {
        "message": "Salut, $name"
      }
    #elseif( $lang == 'es' )
      {
        "message": "Hola, $name"
      }
    #else
      {
        "message": "Hello, $name"
      }
    #end    

See https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/java_s3_code_examples.html#s3_GetObject_java_topic
Section 


https://www.reddit.com/r/vscode/comments/su4ebg/how_to_set_tab_spacing_per_file_type_for_all/
section Get started with buckets and objects

REST Spring Boot and CORS : https://www.baeldung.com/spring-cors

!!!! Some idea
	use the AWS parameter store to indicate if the TODO-s app storage should be JSON file on S3 or Dynamo DB
	use some factories inside the lambdas to determine that :)
	
To create an API Gateway resource with Path Parameters :
	1.  create the "main" resource, for example todos
	2.	select the todos resource and click create resource - this will enable to create a sub-resource
		in the name of the resource provide the path parameter ex: {todoId}

X-Ray vs Cloud Watch as observability mechanisms.
	
	CloudWatch is a common place where we can see the logs of different AWS resources.
	
	For example for a Lambda Function we can do logging using 
	LambdaLogger logger = context.getLogger();
	logger.log("some message")
	(System.out.println may or may not have the same outcome)
	
	Since multiple instances of a lambda function may run at the same time, having 
	a unique log file to check would not be a trivial task.
	
	So AWS provides the CloudWatch. When we to a LabdaLogger.log() in fact we are doing
	a call to some AWS API which will write to CloudWatch logs
	
	CloudWatch has Log Groups - so for a MyLambda lambda function there will be a group
	Log Stream - each instance of the MyLambda function will be a different entry/file in the group.
	
	Note that for example for Lambda Function it's not necessary for us to create a log group.
	AWS seems to do it automatically the first time the function runs.
	
	  
		
Lambda-s and permissions.
	
	Execution role: this specifies what services your lambda can access	
		for example - access DynamoDB, S3, write logs to CloudWatch, add tracing to X-Ray
		
		When creating a LambdaFunction from the Web UI if we do not specify an IAM role 
		as execution role, AWS will create one automatically. It has CloudWatch permissions:
		FirstLambda-role-4vl4e1cp has one policy
			AWSLambdaBasicExecutionRole-6333557d-55de-40b2-9cbd-f6ae76b76339
			{
			    "Version": "2012-10-17",
			    "Statement": [
			        {
			            "Effect": "Allow",
			            "Action": "logs:CreateLogGroup",
			            "Resource": "arn:aws:logs:us-east-1:285469546962:*"
			        },
			        {
			            "Effect": "Allow",
			            "Action": [
			                "logs:CreateLogStream",
			                "logs:PutLogEvents"
			            ],
			            "Resource": [
			                "arn:aws:logs:us-east-1:285469546962:log-group:/aws/lambda/FirstLambda:*"
			            ]
			        }
			    ]
			}
		
		We should probably create a specific Role with the needed permission like
		CloudWatch, DynamoDb access. We should be able to select those from the 
		available Policies provided by AWS 			
		
	
	Resource based policy: this specifies who can access this resource
		for example - for a certain lambda function to be invoked by an API Gateway
		endpoint a policy has to be added to the lambda to permit this.
		
		Note that when binding a Lambda Function to an API Gateway resource/method
		using Web UI , AWS will automatically create the necessary IAM policies for
		the lambda to be called.
		
		For a /todo GET request it creates:
		{
		  "ArnLike": {
		    "AWS:SourceArn": "arn:aws:execute-api:us-east-1:285469546962:r4cwbi98f9/*/GET/todos"
		  }
		} 	
		
		For a /todo/{todoID} so different path, it creates:					
		{
		  "ArnLike": {
		    "AWS:SourceArn": "arn:aws:execute-api:us-east-1:285469546962:r4cwbi98f9/*/GET/todos/*"
		  }
		}
		
		Q:  note that above r4cwbi98f9 is the id of the API Gateway 
			could these be re-united under a single policy to allow all request from
			that specific API Gateway, so all http methods like GET, POST, DELETE, etc
			and all paths ? Although we do not have so many :) 
			
		
////////////////

Create all TODOs related resources for the Web UI version using Manual-Todo prefix
Create all TODOs related resource for the AWS SDK provisioning using SDK-TODO prefix
use iholtea suffix where global unique names are required, like S3 buckets for example

-   Create an API Gateway of type REST API with name manual-todo

-   Creat a resource /footer , check enable CORS. 
	This will automatically add the OPTIONS Http method. 
	Choose Mock as integration type
	Provide response integration type as mock
	in order to be used to display some custom info as the footer of the page.
	Gets 2 query string parameters - lang( for language) and company ( for company name )

-   Deploy the API and link it to a stage
	
	Although without a stage it has a public access link like
	https://95k6wo08hg.execute-api.us-east-1.amazonaws.com
	it cannot be accessed outside AWS console, it will display an Forbidden message
	
	So we need a stage - call it test
	It seems we cannot create a stage without a deployment(? to be confirmed)
	So hit deploy and select *New Stage*, give it a stage name: test
	
	This provides the Invoke URL: https://95k6wo08hg.execute-api.us-east-1.amazonaws.com/test
	Invoke with params: https://95k6wo08hg.execute-api.us-east-1.amazonaws.com/test/footer?lang=ro&company=Apple
	
	We may also set throttling parameters, logs and tracing, etc 
	
-   Create IAM role for execution of lambda
	( specifies what service a lambda function can access )	
	
	Name: Manual-Todo-Lambda-Role
	Attached policies:
		CloudWatchLogsFullAccess
		AmazonDynamoDBFullAccess
		
-	Create LambdaFunction with name ManualTodoLambda
	choose as execution role the one created above instead of letting the UI create a new one.
	
-	Go to the manual-todo API Gateway and create the /todos and /todos/{todoId} resources
	check enable CORS for both
	To create the sub-resource with path parameter /todos/{todoId} hit create a resource
	after selecting the /todos resource - this will create it as a "childe" resource
	provide {todoId} as name
	
	Check the Lambda proxy integration
	Choose lambda function as integration type and select the ManualTodoLamba
	from the drop-down. It will appear by its ARN, since we did not publish the Lambda
	Lambda-s can be published, they may have multiple versions.
	We can create ALIAS-es to point to some version( specific one or $LATEST)
	In order to support multiple environments like TEST, PROD, etc
	
	Since we are using just one environment, it's not mandatory to publish the lambda
	API Gateway will reference it by its ARN and will always invoke the $LATEST uploded code. 		
		
!!!!
	https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway-tutorial.html
	https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html
	or 
	headers: {
      "Access-Control-Allow-Origin": "*", // Required for CORS support to work
      "Access-Control-Allow-Credentials": true, // Required for cookies, authorization headers with HTTPS
    },
	
	For the the execution role of lambda, to allow access to CloudWatch and DynamoDB
	instead of using those build-in AWS policies containing full access to the service
	we could create a custom policy
	
	1.  Open the Policies page of the IAM console.
	2.  Choose Create Policy.
	3.  Choose the JSON tab, and then paste the following custom policy into the JSON editor.
	
	{
	  "Version": "2012-10-17",
	  "Statement": [
	    {
	      "Sid": "Stmt1428341300017",
	      "Action": [
	        "dynamodb:DeleteItem",
	        "dynamodb:GetItem",
	        "dynamodb:PutItem",
	        "dynamodb:Query",
	        "dynamodb:Scan",
	        "dynamodb:UpdateItem"
	      ],
	      "Effect": "Allow",
	      "Resource": "*"
	    },
	    {
	      "Sid": "",
	      "Resource": "*",
	      "Action": [
	        "logs:CreateLogGroup",
	        "logs:CreateLogStream",
	        "logs:PutLogEvents"
	      ],
	      "Effect": "Allow"
	    }
	  ]
	}
	
	4.  Choose Next: Tags.
	5.  Choose Next: Review.
	6.  Under Review policy, for the policy Name, enter lambda-apigateway-policy.
	7.  Choose Create policy.
	
	Create the role:
	1.  Open the Roles page of the IAM console.
	2.  Choose Create role.
	3.  For the type of trusted entity, choose AWS service, then for the use case, choose Lambda.
	4.  Choose Next.
	5.  In the policy search box, enter lambda-apigateway-policy.
	6.  In the search results, select the policy that you created (lambda-apigateway-policy), 
		and then choose Next.
	7.  Under Role details, for the Role name, enter lambda-apigateway-role, then choose Create role.

	Later in the tutorial, you need the Amazon Resource Name (ARN) of the role you just created. 
	On the Roles page of the IAM console, choose the name of your role (lambda-apigateway-role) 
	and copy the Role ARN displayed on the	
	( I think the ARN role is needed if we create the lambda from CLI to provide the execution
	role. In the Web UI i think you can find it in the drop-down )
	
	
	https://fontawesome.com/icons/trash-can?f=sharp&s=regular
	
TODOs in UI

	1.  add order both to items in a todo list and for the todo list
		For Todo list we could use a timestamp ( for now its just a yyyy-mm-dd )
		As items are added as a batch request, we should use a column to order them
		
		what is the "natural order" for PK/SK in Dynamo ?
		the string/int data type order?
		
		NOTE:
			A time-based UUID, also known as the version 1 UUID, is generated using 
			the current time and a unique identifier specific to the computer or network 
			that produces the UUID. The timestamp ensures the UUID is unique, 
			even if multiple UUIDs are generated simultaneously.

			We’ll find two new versions of the standard (v6 and v7) that are time-related 
			in the libraries implemented below.

			Version 1 presents several advantages – the time sorted id is fitter to be a primary
			key in a table, and containing the creation timestamp can help with analysis and debugging. 
			It also has some disadvantages – the chance of collision is slightly higher when generating multiple IDs from the same host. We’ll see if this is an issue later on.
			
			Also, i think it's useful for relational DBs due to the algorithm they use to create
			the ordered index. A complete random Key means a costly insert as the index trees
			need to be rebalanced quite a lot as oposed to an ordered key like a sequence
			
		https://www.baeldung.com/java-generating-time-based-uuids	
		
		<dependency>
		    <groupId>com.fasterxml.uuid</groupId>
		    <artifactId>java-uuid-generator</artifactId>
		    <version>4.1.0</version>
		</dependency>
		
		System.out.println("UUID Version 1: " + Generators.timeBasedGenerator().generate());
		System.out.println("UUID Version 6: " + Generators.timeBasedReorderedGenerator().generate());
		System.out.println("UUID Version 7: " + Generators.timeBasedEpochGenerator().generate());
		
		Single Table idea
		Partition key:  userEmail
			as DynamoDb is using a hash function to determine the "bucket" where the records
			will be written, it would be preferable that the PK would be uniformly distributed
			So and UUID would be better than an email or name ( more random )
			But the user logs with the email how to get the UUID ?
			( would having a separate table with just email and uuid and email PK worth it 
			to do once per login query ?)
			Then the email will be part of the JSON token sent with every request ?
		Sort Key
			L/I is its a list or item to be able to get just the lists
			#list-uuid
			#item_uuid
			For a list:   SK:  L#list-uuid   // query Lists by starts_with l#
			For an item:  SK:  I#list-uuid#item-uuid
		
		Another thing to keep in mind is that you pay for DynamoDB by RCU ( read units )
		So even if record is small ( 1 RCU = up to KB ) we still pay 1 or 0.5 RCU per read.
		So it might be more cost effective to have duplicate data in records in a table
		than reading smaller data from 2 different tables of from 2 different queries.	
		On the other hand each update of a record means it is first read by its PK(+SK)
		attributes updated and then written back - to keep in mind for frequent updates or records
		
				   
	2.	implement authorization for delete / update operations
		As the user email is server side an PK for TodoList-s, the operations will not work if a bad actor
		is trying to delete TodoList-s using random Uuids
		If we keep the TodoItem with PK List Uuid, then we need to check if the List UUID belongs to the
		logged in user
		( this might be a pro to use only user email as PK and a hierarchical SK )
		
		
	3.	each operation on a TodoList, like delete/check/update/add new item should modify
		the TodoList lastUpdate field which should be used to order the lists	
		
		i think we could use a local secondary index being the timestamp of last update
		( but is this a good idea, to update so often the field that is an index ? )
		Maybe it's a better idea to just scan within for the users all the todo lists
		
		In fact we should set the lastUpdate when a user clicks to see the details of a todoList
		to minimize operations, especially if the timestamp would be a LSI ( local secondary index )
		update it on the server only if the lastUpdate is not the same day as in the database
		so we do not update it more times per day/session
		
		does the LSI values need to unique ( as the SK within a partition ) ?
		if so, we could make the LSI date#uuid , to be ordered by date ( but we need it in inverse order :) )
		
		AWS docs: "When you add or update a table item, DynamoDB updates all local secondary indexes that are affected. 
		If the indexed attributes are defined in the table, the local secondary indexes grow too." 
	
	3.  handle DynamoDbException in Repository implementation. 
		Throw custom runtime exceptions or catch them in business layer and create appropriate response to client 
		
	4.  Check the "responsive-ness" of the design, too much space to the right on smaller resolutions	
		
	4.	add USage plan with API key - check internets
		https://www.youtube.com/watch?v=AxhbAx4PTow	
		
	5.  add some pagination to either lists or items or both	
	
	9.	Lower priority as when fetching the list of Todos we might not fetch all the List attributes
		( if they might contain lots of data ):
		when fetching a TodoList by ID, we should just fetch its Items
		as the TodoList details are already stored in the globalData.todos
	
		
https://www.discworldemporium.com/reading-order/

Fa programare la GTT motors pt ITP si revizie



		





        
